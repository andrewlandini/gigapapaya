import {
  generateObject,
  experimental_generateVideo as generateVideo,
} from 'ai';
import { z } from 'zod';
import { getTextModel, getVideoModel } from './provider';
import { IDEA_AGENT_PROMPT, SCENES_AGENT_PROMPT, VEO3_PROMPTER_PROMPT } from '../prompts';
import { saveVideo } from './video-storage';
import type { VideoIdea, ScenesResult, Video, GenerationOptions } from '../types';

// Zod schemas for structured output validation
const videoIdeaSchema = z.object({
  title: z.string().describe('A concise, descriptive title for the video concept'),
  description: z.string().describe('A detailed 2-3 sentence description of the video'),
  style: z.string().describe('The visual style (e.g., cinematic, documentary, animated)'),
  mood: z.string().describe('The emotional tone (e.g., uplifting, suspenseful, peaceful)'),
  keyElements: z.array(z.string()).describe('3-5 specific visual elements that should appear'),
});

const sceneSchema = z.object({
  index: z.number().describe('Scene number'),
  prompt: z.string().describe('Ultra-detailed scene description for video generation'),
  duration: z.number().describe('Duration in seconds'),
  notes: z.string().describe('Technical notes about camera, lighting, and composition'),
});

const scenesResultSchema = z.object({
  scenes: z.array(sceneSchema).describe('Array of 3-5 scene descriptions'),
  consistencyNotes: z.string().describe('Guidance on maintaining visual consistency'),
});

/**
 * Agent 1: Generate creative video idea from user input
 */
export async function executeIdeaAgent(
  userInput: string,
  config?: { model?: string; prompt?: string }
): Promise<VideoIdea> {
  const modelId = config?.model || 'anthropic/claude-sonnet-4.5';
  const systemPrompt = config?.prompt || IDEA_AGENT_PROMPT;

  console.log('\nğŸ¨ IDEA AGENT: Starting...');
  console.log(`ğŸ“ User Input: "${userInput}"`);
  console.log(`ğŸ¤– Model: ${modelId}\n`);

  const result = await generateObject({
    model: getTextModel(modelId),
    temperature: 1,
    schema: videoIdeaSchema,
    prompt: `${systemPrompt}\n\nUser Input: ${userInput}`,
  });

  console.log('âœ… IDEA AGENT: Complete');
  console.log('ğŸ“‹ Generated Idea:', JSON.stringify(result.object, null, 2));
  console.log('');

  return result.object as VideoIdea;
}

// Base prompt appended to all scene agent calls (not shown in UI)
const SCENE_AGENT_BASE = `

SCENE CONSISTENCY RULES (MANDATORY):
- Choose ONE cinematic style/look for ALL scenes and repeat it verbatim in every prompt (e.g., "shot on ARRI Alexa, warm amber grade, shallow depth of field")
- Characters must be RECOGNIZABLE across scenes â€” same age, ethnicity, build, hair, and clothing. Re-describe these identity details every time. But allow their physical STATE to evolve naturally.
- If scenes share a location, describe the environment with the same details each time (same lighting conditions, same set dressing, same color palette)
- Scenes must feel like they belong to the same film â€” consistent color temperature, grain, contrast, and aspect ratio

SHOT VARIETY (CRITICAL â€” NO JUMP CUTS):
- Every scene MUST use a DIFFERENT shot type and camera angle. If scene 1 is a medium shot, scene 2 must be a close-up or wide shot â€” NEVER two medium shots in a row.
- Vary across these: wide/establishing, medium, close-up, extreme close-up, over-the-shoulder, low angle, high angle, profile/side angle
- Vary camera movement too: if scene 1 is a slow push, scene 2 should be static or an orbit â€” NOT another push
- Think like an EDITOR cutting a scene together. When these clips play back-to-back, each cut should show a meaningfully different framing. Same angle + same framing = jump cut = amateur.
- Example for 3 scenes: Scene 1: wide shot, static â†’ Scene 2: close-up on face, slow push â†’ Scene 3: over-shoulder medium, handheld

CRITICAL PROMPT STRUCTURE FOR EACH SCENE:
[SHOT TYPE] + [SUBJECT with full physical description] + [PRIMARY ACTION + natural body language] + [STYLE - identical across scenes] + [CAMERA MOVEMENT] + [AUDIO CUES]

Example: Medium shot, cyberpunk hacker (male, mid-30s, shaved head, black hoodie, pale skin, cybernetic arm) typing frantically, neon reflections on face, blade runner aesthetic, shot on ARRI Alexa with anamorphic lens, teal and orange color grade, slow push in, Audio: mechanical keyboard clicks, distant sirens

Rules:
- Front-load the important stuff â€” Veo 3 weights early words more heavily
- Lock down the "what" then iterate on the "how"
- ONE primary action per scene â€” the reason this shot exists. But allow natural secondary behavior within it (breathing, glancing, wincing, adjusting grip). "A man runs" is too simple. "A man runs while pressing a bleeding wound on his ribs" is one action with subtext.
- Specific > Creative â€” "Walking sadly" < "shuffling with hunched shoulders"
- Audio cues are essential â€” give the video a realistic feel
- ALWAYS include full character descriptions â€” never use "the character" or "the person", always redescribe them

Camera movements that work:
- Slow push/pull (dolly in/out)
- Orbit around subject
- Handheld follow
- Static with subject movement

Avoid:
- Complex combinations ("pan while zooming during a dolly")
- Unmotivated movements
- Multiple focal points
- Vague character references â€” always fully describe every person in frame

Style references that consistently deliver:
- "Shot on [specific camera]" (use the SAME camera for all scenes)
- "[Director name] style" (use the SAME director reference for all scenes)
- "[Movie] cinematography" (use the SAME film reference for all scenes)
- Specific color grading terms (use the SAME grade for all scenes)

DIALOGUE RULES (MANDATORY):
- Almost ALL videos should feature talking unless the concept genuinely has no speaking characters (pure nature, abstract, etc.)
- Include natural spoken dialogue in quotes within each scene prompt
- Write dialogue as SPOKEN WORDS â€” conversational, not literary. Use contractions always, natural pauses, filler words where they fit. Real people don't speak in complete, grammatically perfect sentences.
- Match dialogue to the mood: tense scenes = clipped, urgent. Calm scenes = wandering, trailing off. Comedy = matter-of-fact about absurd things.
- Dialogue across scenes should feel like one continuous conversation â€” each scene picks up roughly where the last left off.
- HARD WORD COUNT LIMIT: A person speaks ~2.5 words per second. For the scene duration, count the words in your dialogue and MAKE SURE they fit. An 8-second scene = MAX 15-18 words of dialogue (leave room for pauses and breathing). A 6-second scene = MAX 12 words. A 4-second scene = MAX 8 words. If your dialogue is longer than this, CUT IT DOWN. The video will literally cut off mid-sentence if you write too much. Shorter is always better â€” one punchy line beats a paragraph that gets cut off.
- BANNED WORDS: NEVER use "subtitle", "subtitles", "subtitled", "caption", "captions", or "text overlay" in any prompt. Veo 3.1 will render literal subtitle text on screen if these words appear. Write dialogue directly in quotes instead.`;

/**
 * Agent 2: Generate scene breakdown from video idea
 */
export async function executeScenesAgent(
  idea: VideoIdea,
  numScenes: number = 3,
  config?: { model?: string; prompt?: string },
  duration: number = 8,
  noMusic: boolean = false
): Promise<ScenesResult> {
  const modelId = config?.model || 'anthropic/claude-sonnet-4.5';
  const systemPrompt = config?.prompt || SCENES_AGENT_PROMPT;

  console.log('\nğŸ¬ SCENES AGENT: Starting...');
  console.log(`ğŸ“‹ Idea: ${idea.title}`);
  console.log(`ğŸ¯ Target: ${numScenes} scenes, ${duration}s each`);
  console.log(`ğŸ¤– Model: ${modelId}\n`);

  const ideaSummary = `
Title: ${idea.title}
Description: ${idea.description}
Visual Style: ${idea.style}
Mood: ${idea.mood}
Key Elements: ${idea.keyElements.join(', ')}
`;

  const maxWords = duration <= 4 ? 8 : duration <= 6 ? 12 : 18;
  const durationGuidance = `

SCENE DURATION: Each scene is EXACTLY ${duration} seconds long. This is a HARD constraint:

DIALOGUE WORD LIMIT (NON-NEGOTIABLE):
- People speak ~2.5 words per second
- ${duration}s = MAXIMUM ${maxWords} words of dialogue per scene
- COUNT EVERY WORD. If dialogue exceeds ${maxWords} words, the video WILL cut off mid-sentence
- ${duration <= 4 ? 'At 4s you get ONE short sentence. Example: "Wait, did you hear that?" (5 words)' : duration <= 6 ? 'At 6s you get ONE medium sentence. Example: "I don\'t think we should be here right now" (9 words)' : 'At 8s you get 1-2 short sentences. Example: "So picture this, we line the hallway with lawyers\' cards. Greg, thoughts?" (12 words)'}
- When in doubt, SHORTER. A 10-word line that lands is better than an 18-word line that gets cut off

PHYSICAL PACING:
- Walking: ~${Math.round(duration * 1.4)}m in ${duration}s. Running: ~${Math.round(duration * 3)}m
- Slow camera push: ~${Math.round(duration * 0.3)}m in ${duration}s
- Specify movement speed explicitly (slow walk, brisk pace, sprinting)
- Everything described must be PHYSICALLY ACHIEVABLE in ${duration} real seconds`;

  const musicNote = noMusic ? `\n\nNO MUSIC: The user has disabled music. Do NOT include any background music, soundtrack, or musical score in audio cues. Only include diegetic sounds â€” ambient noise, dialogue, footsteps, environmental sounds, etc. The user will add music in post-production.` : '';

  const sceneCountGuidance: Record<number, string> = {
    2: `NARRATIVE STRUCTURE (2 SCENES):
This is a BEFORE/AFTER or SETUP/PAYOFF. Two shots that create meaning through contrast.
- Scene 1: Establish the situation, character, and tension
- Scene 2: The punchline, reveal, consequence, or transformation
Think: cause â†’ effect. Question â†’ answer. Calm â†’ chaos. The cut between them IS the story.`,
    3: `NARRATIVE STRUCTURE (3 SCENES):
Classic three-act structure compressed into 3 shots. Beginning, middle, end.
- Scene 1: ESTABLISH â€” set the world, introduce the character, show the status quo. Wide or medium shot.
- Scene 2: ESCALATE â€” something changes, goes wrong, or intensifies. Move closer (close-up or over-shoulder).
- Scene 3: RESOLVE â€” the payoff, punchline, consequence, or emotional landing. Different angle that recontextualizes what we saw.
Each scene must ADVANCE the story. No two scenes should show the same beat.`,
    4: `NARRATIVE STRUCTURE (4 SCENES):
Four shots gives you room for a proper dramatic arc with a twist or complication.
- Scene 1: ESTABLISH â€” world, character, context. Set the tone.
- Scene 2: DEVELOP â€” deepen the situation, reveal a detail, build tension or comedy.
- Scene 3: COMPLICATE â€” the twist, the interruption, the thing that changes everything.
- Scene 4: LAND â€” the payoff, the reaction, the consequence. End on the strongest image.
Think of it as: situation â†’ deepening â†’ disruption â†’ aftermath.`,
    5: `NARRATIVE STRUCTURE (5 SCENES):
Five shots is a short film. You have room to BREATHE â€” use it for rhythm and pacing.
- Scene 1: OPEN â€” establishing shot, set the world. Give context.
- Scene 2: INTRODUCE â€” show who we're following and what they're doing.
- Scene 3: DEVELOP â€” build, complicate, or deepen. Add a new element or tension.
- Scene 4: CLIMAX â€” the peak moment, the biggest reaction, the turning point.
- Scene 5: RESOLVE â€” aftermath, consequence, punchline, or quiet denouement.
Vary the energy: don't make every scene intense. Use contrast â€” quiet/loud, wide/close, fast/slow.`,
  };

  const sceneNarrative = sceneCountGuidance[numScenes] || (numScenes >= 6 ? `NARRATIVE STRUCTURE (${numScenes} SCENES):
With ${numScenes} shots you're making a proper short film. Think in SEQUENCES, not individual shots.
- Opening sequence (scenes 1-2): Establish world, character, tone
- Development (scenes 3-${Math.floor(numScenes * 0.6)}): Build the story, add complications, deepen characters
- Climax (scene ${Math.floor(numScenes * 0.7)}-${Math.floor(numScenes * 0.8)}): Peak tension or comedy
- Resolution (final ${numScenes - Math.floor(numScenes * 0.8)} scenes): Payoff, consequence, ending
Vary pacing â€” not every scene should be the same intensity. Use quiet moments to make loud ones hit harder. Think about rhythm like music: verse, chorus, bridge, chorus.` : sceneCountGuidance[3]);

  const result = await generateObject({
    model: getTextModel(modelId),
    temperature: 1,
    schema: scenesResultSchema,
    prompt: `${systemPrompt}${SCENE_AGENT_BASE}${durationGuidance}\n\n${sceneNarrative}${musicNote}\n\nVideo Idea:\n${ideaSummary}\n\nGenerate ${numScenes} scenes, each ${duration} seconds long. Everything described must fit within ${duration} seconds of real time. Do not self-censor or water down the creative concept â€” commit fully to the idea.`,
  });

  console.log('âœ… SCENES AGENT: Complete');
  console.log(`ğŸ“¹ Generated ${result.object.scenes.length} scenes:`);
  result.object.scenes.forEach((scene, i) => {
    console.log(`\n  Scene ${i + 1}:`);
    console.log(`  Prompt: ${scene.prompt.substring(0, 100)}...`);
    console.log(`  Duration: ${scene.duration}s`);
  });
  console.log(`\nğŸ¨ Consistency Notes: ${result.object.consistencyNotes}`);
  console.log('');

  return result.object as ScenesResult;
}

/**
 * Agent 2.5: Veo 3 Prompting Expert â€” optimize scene prompts for Veo 3.1
 */
const veo3OptimizedSchema = z.object({
  optimizedPrompts: z.array(z.string()).describe('Optimized prompts for Veo 3.1, one per scene in the same order'),
});

export async function executeVeo3PrompterAgent(
  scenePrompts: string[],
  style: string,
  mood: string,
  consistencyNotes: string,
  duration: number = 8,
  noMusic: boolean = false
): Promise<string[]> {
  console.log('\nğŸ¬ VEO3 PROMPTER: Starting...');
  console.log(`ğŸ“¹ Optimizing ${scenePrompts.length} scene prompts for Veo 3.1 (${duration}s each)`);
  console.log(`ğŸ¨ Style: ${style}, Mood: ${mood}\n`);

  const scenesText = scenePrompts
    .map((p, i) => `Scene ${i + 1}: ${p}`)
    .join('\n\n');

  const veoMaxWords = duration <= 4 ? 8 : duration <= 6 ? 12 : 18;
  const veoMusicNote = noMusic ? ' NO MUSIC in audio cues â€” only diegetic/ambient sounds, dialogue, and environmental audio. No soundtrack, no score, no background music.' : '';
  const durationNote = `\n\nDURATION CONSTRAINT (CRITICAL): Each scene is ${duration} seconds. DIALOGUE HARD LIMIT: MAX ${veoMaxWords} words per scene. Count every word. At 2.5 words/second, ${veoMaxWords} words = ${(veoMaxWords / 2.5).toFixed(1)}s of speaking, which leaves breathing room in a ${duration}s clip. If dialogue exceeds ${veoMaxWords} words, the video WILL cut off mid-sentence. One punchy line beats a monologue that gets truncated. Also specify movement speed explicitly.${veoMusicNote}`;

  const result = await generateObject({
    model: getTextModel('anthropic/claude-sonnet-4.5'),
    schema: veo3OptimizedSchema,
    prompt: `${VEO3_PROMPTER_PROMPT}${durationNote}\n\nVisual Style: ${style}\nMood: ${mood}\nConsistency Notes: ${consistencyNotes}\n\nScene prompts to optimize:\n\n${scenesText}\n\nOptimize each prompt for Veo 3.1. Return exactly ${scenePrompts.length} optimized prompts in the same order. Each scene is ${duration}s â€” everything must fit.`,
  });

  console.log('âœ… VEO3 PROMPTER: Complete');
  result.object.optimizedPrompts.forEach((p, i) => {
    console.log(`\n  Scene ${i + 1} (optimized): ${p.substring(0, 120)}...`);
  });
  console.log('');

  return result.object.optimizedPrompts;
}

/**
 * Agent 3: Generate video from scene prompt using AI Gateway + Veo 3.1
 */
export async function executeVideoAgent(
  scenePrompt: string,
  style: string,
  mood: string,
  options: GenerationOptions,
  sceneIndex: number
): Promise<Video> {
  console.log(`\nğŸ¥ VIDEO AGENT: Starting for scene ${sceneIndex + 1}...`);
  console.log(`ğŸ“ Scene Prompt: ${scenePrompt.substring(0, 150)}...`);
  console.log(`ğŸ¨ Style: ${style}, Mood: ${mood}`);
  console.log(`âš™ï¸  Options: ${options.aspectRatio}, ${options.duration}s`);
  console.log('â³ Generating video (this may take 2-5 minutes)...\n');

  // Prompt is already optimized by the Veo3 Prompter agent (or passed directly in direct mode)
  const enhancedPrompt = scenePrompt;
  console.log(`ğŸ¬ Final Prompt: ${enhancedPrompt.substring(0, 200)}...\n`);

  const startTime = Date.now();

  try {
    // Generate video via AI Gateway using Veo 3.1
    const { videos } = await generateVideo({
      model: getVideoModel('google/veo-3.1-generate-001'),
      prompt: enhancedPrompt,
      aspectRatio: options.aspectRatio,
      duration: options.duration,
    });

    const elapsedTime = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`âœ… VIDEO AGENT: Video generated in ${elapsedTime}s`);
    console.log(`ğŸ“Š Received ${videos.length} video(s)`);

    if (videos.length === 0) {
      throw new Error('No video was generated');
    }

    // Save first video to storage
    const videoFile = videos[0];
    console.log('ğŸ’¾ Saving video to storage...');

    const video = await saveVideo(videoFile, {
      prompt: enhancedPrompt,
      duration: options.duration,
      aspectRatio: options.aspectRatio,
    });

    console.log(`âœ… Video saved: ${video.filename}`);
    console.log(`ğŸ“Š Size: ${(video.size / (1024 * 1024)).toFixed(2)} MB`);
    console.log(`ğŸ”— URL: ${video.url}\n`);

    return video;
  } catch (error) {
    console.error(`âŒ VIDEO AGENT: Failed to generate video for scene ${sceneIndex + 1}`);
    console.error('Error:', error);
    throw error;
  }
}

/**
 * Execute full multi-agent workflow
 */
export async function executeFullWorkflow(
  userInput: string,
  options: GenerationOptions
): Promise<{
  idea: VideoIdea;
  scenes: ScenesResult;
  videos: Video[];
}> {
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ğŸš€ STARTING MULTI-AGENT VIDEO GENERATION WORKFLOW');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  // Agent 1: Generate idea
  const idea = await executeIdeaAgent(userInput);

  // Agent 2: Generate scenes
  const scenesResult = await executeScenesAgent(idea, options.numScenes || 3, undefined, options.duration || 8, options.noMusic || false);

  // Agent 3: Generate videos for each scene
  const videos: Video[] = [];
  for (let i = 0; i < scenesResult.scenes.length; i++) {
    const scene = scenesResult.scenes[i];
    try {
      const video = await executeVideoAgent(
        scene.prompt,
        idea.style,
        idea.mood,
        options,
        i
      );
      videos.push(video);
    } catch (error) {
      console.error(`âš ï¸  Skipping scene ${i + 1} due to error`);
      // Continue with next scene
    }
  }

  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log(`âœ… WORKFLOW COMPLETE: ${videos.length}/${scenesResult.scenes.length} videos generated`);
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  return {
    idea,
    scenes: scenesResult,
    videos,
  };
}
